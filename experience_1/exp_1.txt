В данном опыте будет происходить глубокое q-обучение двузвенного ограниченного манипулятора с применением нейронной сети с функцией активации "гиперболический тангенс" и двумя выходами.
Так же в плане настроить среду на отсеивания повторяющихся действий и создание "шума" для приближения математической среды к реальной
envernoment.py - файл с класом среды env()
TESTS.py - файл для тестов функций и классов
dqn_agent.py - класс агента и финальный скрипт

1) Настройка среды
1.1) Настройка перевода из декартовой системы координат в полярную
1.1.1) Функция должна выводить значение угла fi в интервале [0, 360) гр.
1.2) Создаём метки на "холсте", коорые упростят визуализацию
1.2.1) Привести в порядок систему координат, сделать так, чтобы отсчёт начинался из центра
1.2.2) Создание пути по которому проходит конец манипулятора #ОТЛОЖЕНО
1.3) Наладить нормализацию: сделать так, чтобы у каждого элемента нормализованного тензора были значения от 0 до 1
1.4) Определить выражение всех углов в среде в радианах 
1.5) Переписать функцию step с учётом того, что на вход будет поступать список заначений преобразованных функцией гиперболического тангенса
1.5.1) Не забыть про ограничения
1.6) Изменем функцию награды так, чтобы q-таблица находилась в диапазоне от 0 до 1 #важно 

2) Настройка агента
2.1) Создадим модель с использованием функцианального API keras
2.1.1) Разобраться с тем, что такое функции активации

3) Решено было отказаться от функции активации гепорболического тангенса и заменить его на линейную функцию, но при этом оставить так называемую многоловость функции.
Это было сделано для того, чтобы путём нейросети предсказывать не само действие, q-таблицу.

4) При первом тесте была допущена ошибка: нейросеть обучалась только на данных, полученных от угла q1, но при этом решение получилось достаточно точным,
что его можно было принять за недостаток времени обучения. Дальнейшие эксперименты будут проводится уже на модели манипулятора состоящих из 3 звеньев 